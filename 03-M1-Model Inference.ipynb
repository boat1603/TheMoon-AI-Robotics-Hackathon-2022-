{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d4fbc64-7b88-4c9a-82fc-2ec249171016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# Ref: https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/efficientnet.py\n",
    "# Install: pip install timm\n",
    "import timm\n",
    "from timm.models.efficientnet import default_cfgs \n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import transforms as T\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e002aaa4-adf2-4cbe-afc3-a8e047bac972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>npy_path</th>\n",
       "      <th>area_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./datasets/training_data_5d/test/test_0000_000...</td>\n",
       "      <td>0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./datasets/training_data_5d/test/test_0001_000...</td>\n",
       "      <td>0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./datasets/training_data_5d/test/test_0002_000...</td>\n",
       "      <td>0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./datasets/training_data_5d/test/test_0003_000...</td>\n",
       "      <td>0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./datasets/training_data_5d/test/test_0004_000...</td>\n",
       "      <td>0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11811</th>\n",
       "      <td>./datasets/training_data_5d/test/test_0564_179...</td>\n",
       "      <td>0564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11812</th>\n",
       "      <td>./datasets/training_data_5d/test/test_0564_180...</td>\n",
       "      <td>0564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11813</th>\n",
       "      <td>./datasets/training_data_5d/test/test_0564_181...</td>\n",
       "      <td>0564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11814</th>\n",
       "      <td>./datasets/training_data_5d/test/test_0564_182...</td>\n",
       "      <td>0564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11815</th>\n",
       "      <td>./datasets/training_data_5d/test/test_0564_183...</td>\n",
       "      <td>0564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11816 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                npy_path area_id\n",
       "0      ./datasets/training_data_5d/test/test_0000_000...    0000\n",
       "1      ./datasets/training_data_5d/test/test_0001_000...    0001\n",
       "2      ./datasets/training_data_5d/test/test_0002_000...    0002\n",
       "3      ./datasets/training_data_5d/test/test_0003_000...    0003\n",
       "4      ./datasets/training_data_5d/test/test_0004_000...    0004\n",
       "...                                                  ...     ...\n",
       "11811  ./datasets/training_data_5d/test/test_0564_179...    0564\n",
       "11812  ./datasets/training_data_5d/test/test_0564_180...    0564\n",
       "11813  ./datasets/training_data_5d/test/test_0564_181...    0564\n",
       "11814  ./datasets/training_data_5d/test/test_0564_182...    0564\n",
       "11815  ./datasets/training_data_5d/test/test_0564_183...    0564\n",
       "\n",
       "[11816 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npy_path = glob(\"./datasets/training_data_5d/test/*.npy\")\n",
    "df = pd.Series(npy_path,name=\"npy_path\").to_frame()\n",
    "# df['classes'] = df['npy_path'].apply(lambda x: int(x.split('.')[1][-1])-1)\n",
    "# df['area_id'] = df['npy_path'].apply(lambda x: x.split('_')[2])\n",
    "df['area_id'] = df['npy_path'].apply(lambda x: x.split('_')[3])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "493abab3-4390-44d6-ac59-6c68409ab18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Loader\n",
    "class SatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,df):\n",
    "        self.npy_path = list(df['npy_path'])\n",
    "        self.area_id = list(df['area_id'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.npy_path)\n",
    "    def __getitem__(self, idx):\n",
    "        data = np.load(self.npy_path[idx])\n",
    "        data = torch.from_numpy(np.swapaxes(data, -3, -1)).float()\n",
    "        return {'image': data, 'area_id': self.area_id[idx]}\n",
    "\n",
    "test_dataset = SatDataset(df)\n",
    "\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 1024\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa967f0b-54fd-43fe-a5f6-11f24e97d299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class ClassifierModel(torch.nn.Module):\n",
    "#     def __init__(self,num_class=4):\n",
    "#         super(ClassifierModel, self).__init__() \n",
    "#         self.backbone = torch.nn.Sequential(\n",
    "#             torch.nn.Conv2d(36, 48, kernel_size=5),\n",
    "#             torch.nn.BatchNorm2d(48),\n",
    "#             torch.nn.LeakyReLU(),\n",
    "#             torch.nn.Conv2d(48, 64, kernel_size=5),\n",
    "#             torch.nn.BatchNorm2d(64),\n",
    "#             torch.nn.LeakyReLU(),\n",
    "#             torch.nn.Conv2d(64, 128, kernel_size=5),\n",
    "#             torch.nn.BatchNorm2d(128),\n",
    "#             torch.nn.LeakyReLU(),\n",
    "#             torch.nn.Conv2d(128, 256, kernel_size=4),\n",
    "#             torch.nn.LeakyReLU(),\n",
    "#             torch.nn.Flatten()\n",
    "#             )\n",
    "#         self.classifier = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(256, num_class),\n",
    "#             torch.nn.BatchNorm1d(num_class),\n",
    "#             # torch.nn.Softmax(dim=1)\n",
    "#             )\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.backbone(x)\n",
    "#         x = self.classifier(x)\n",
    "#         return x\n",
    "    \n",
    "class ClassifierModel(torch.nn.Module):\n",
    "    def __init__(self,num_class=4):\n",
    "        super(ClassifierModel, self).__init__() \n",
    "        self.backbone = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(5, 5, kernel_size=3, padding='same', bias = False),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.BatchNorm2d(5),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(5, 5, kernel_size=3, padding='same', bias = False),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.BatchNorm2d(5),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(5, 5, kernel_size=3, padding='same', bias = False),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.AvgPool2d(2),\n",
    "            torch.nn.Flatten()\n",
    "            )\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(5*12, 16),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(16, num_class),\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.cat([self.backbone(x[:,i*5:i*5+5]) for i in range(12)],axis=-1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "model = ClassifierModel()\n",
    "x = torch.rand(5,60,16,16)\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "063cfebf-1278-4e30-89b1-bca06efc37b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierModel(\n",
       "  (backbone): Sequential(\n",
       "    (0): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (11): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=60, out_features=16, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=16, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ClassifierModel()\n",
    "model.load_state_dict(torch.load('./weight/M1-classifier_model_checkpoint_add_dropout/best_checkpoint.pth.tar')['state_dict'])\n",
    "model.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3c723e82-c072-4b32-8bbb-42eca2c25e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = []\n",
    "label_masks_score = []\n",
    "area_ids = []\n",
    "for batch in test_loader:\n",
    "    batch_sz = batch['image'].shape[0]\n",
    "    \n",
    "    img = batch['image'].cuda()\n",
    "    with torch.no_grad():\n",
    "        logits = model(img).cpu().softmax(axis=1).numpy()\n",
    "    pred_label += [logits]\n",
    "    area_ids += batch['area_id']\n",
    "    label_masks_score += [(img.cpu().numpy()!=0).reshape((batch_sz,-1)).sum(axis=1)/np.prod(batch['image'].shape[1:])]\n",
    "pred_label = np.concatenate(pred_label)\n",
    "label_masks_score = np.concatenate(label_masks_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "50c2bbc7-958b-40dc-8f8d-a048d6760f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = dict()\n",
    "for area_id,logit,mask_score in zip(area_ids,pred_label,label_masks_score):\n",
    "    if area_id in pred_dict.keys():\n",
    "        pred_dict[area_id] += mask_score*(logit)\n",
    "    else:\n",
    "        pred_dict[area_id] = mask_score*logit\n",
    "pred_dict = {int(k):np.argmax(v) for k,v in pred_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c46d6b2d-b38c-4c33-b2db-804026a5df9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crop_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>564 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     crop_type\n",
       "0            1\n",
       "1            3\n",
       "2            1\n",
       "3            2\n",
       "4            1\n",
       "..         ...\n",
       "560          1\n",
       "561          1\n",
       "562          1\n",
       "563          1\n",
       "564          3\n",
       "\n",
       "[564 rows x 1 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output = pd.Series(pred_dict,name='crop_type').to_frame()\n",
    "df_output['crop_type'] += 1\n",
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0015832a-b44a-4b40-bac6-c80db822b0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.to_csv(\"./submissions/M1_DeepLearningClassification_addDropout_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "47b8a1b9-0864-45ef-9e1a-be78a19bea0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    218\n",
       "2    158\n",
       "3    157\n",
       "4     31\n",
       "Name: crop_type, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output['crop_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746e7a1c-8a72-45ca-bc2d-091eb98131fa",
   "metadata": {},
   "source": [
    "# Predict in Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac851b2-0242-46e9-bd5d-6039280af8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>npy_path</th>\n",
       "      <th>classes</th>\n",
       "      <th>area_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./datasets/training_data_5d/train/train_0000_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./datasets/training_data_5d/train/train_0001_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./datasets/training_data_5d/train/train_0001_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./datasets/training_data_5d/train/train_0002_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./datasets/training_data_5d/train/train_0002_0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>./datasets/training_data_5d/train/train_1315_0...</td>\n",
       "      <td>2</td>\n",
       "      <td>1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>./datasets/training_data_5d/train/train_1316_0...</td>\n",
       "      <td>2</td>\n",
       "      <td>1316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>./datasets/training_data_5d/train/train_1316_0...</td>\n",
       "      <td>2</td>\n",
       "      <td>1316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5917</th>\n",
       "      <td>./datasets/training_data_5d/train/train_1316_0...</td>\n",
       "      <td>2</td>\n",
       "      <td>1316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5918</th>\n",
       "      <td>./datasets/training_data_5d/train/train_1316_0...</td>\n",
       "      <td>2</td>\n",
       "      <td>1316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5919 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               npy_path  classes area_id\n",
       "0     ./datasets/training_data_5d/train/train_0000_0...        0    0000\n",
       "1     ./datasets/training_data_5d/train/train_0001_0...        0    0001\n",
       "2     ./datasets/training_data_5d/train/train_0001_0...        0    0001\n",
       "3     ./datasets/training_data_5d/train/train_0002_0...        0    0002\n",
       "4     ./datasets/training_data_5d/train/train_0002_0...        0    0002\n",
       "...                                                 ...      ...     ...\n",
       "5914  ./datasets/training_data_5d/train/train_1315_0...        2    1315\n",
       "5915  ./datasets/training_data_5d/train/train_1316_0...        2    1316\n",
       "5916  ./datasets/training_data_5d/train/train_1316_0...        2    1316\n",
       "5917  ./datasets/training_data_5d/train/train_1316_0...        2    1316\n",
       "5918  ./datasets/training_data_5d/train/train_1316_0...        2    1316\n",
       "\n",
       "[5919 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npy_path = glob(\"./datasets/training_data_5d/train/*.npy\")\n",
    "df = pd.Series(npy_path,name=\"npy_path\").to_frame()\n",
    "df['classes'] = df['npy_path'].apply(lambda x: int(x.split('.')[1][-1])-1)\n",
    "# df['area_id'] = df['npy_path'].apply(lambda x: x.split('_')[2])\n",
    "df['area_id'] = df['npy_path'].apply(lambda x: x.split('_')[3])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b40e5b1f-3e96-4944-8537-3eaff02cd2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5446, 3), (473, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_id,test_id = train_test_split(df['area_id'].unique(), test_size=0.1, random_state=42)\n",
    "\n",
    "# df_train, df_val = train_test_split(df, test_size=0.1, random_state=42)\n",
    "df_train = df.loc[[(i in train_id) for i in df['area_id']]]\n",
    "df_val = df.loc[[(i in test_id) for i in df['area_id']]]\n",
    "\n",
    "df_train.shape,df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5a4c63d-f6c6-473d-8a74-3c919afbc749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Loader\n",
    "class SatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,df):\n",
    "        self.npy_path = list(df['npy_path'])\n",
    "        self.label = list(df['classes'])\n",
    "        self.area_id = list(df['area_id'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.npy_path)\n",
    "    def __getitem__(self, idx):\n",
    "        data = np.load(self.npy_path[idx])\n",
    "        data = torch.from_numpy(np.swapaxes(data, -3, -1)).float()\n",
    "        return {'image': data, 'label': self.label[idx],'area_id':self.area_id[idx]}\n",
    "\n",
    "val_dataset = SatDataset(df_val)\n",
    "\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 1024\n",
    "test_loader  = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2df795b9-ecc0-45b6-85b5-00297ce39c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = []\n",
    "label_masks_score = []\n",
    "area_ids = []\n",
    "\n",
    "for batch in test_loader:\n",
    "    batch_sz = batch['image'].shape[0]\n",
    "    \n",
    "    img = batch['image'].cuda()\n",
    "    with torch.no_grad():\n",
    "        logits = model(img).cpu().softmax(axis=1).numpy()\n",
    "    pred_label += [logits]\n",
    "    area_ids += batch['area_id']\n",
    "    label_masks_score += [(img.cpu().numpy()!=0).reshape((batch_sz,-1)).sum(axis=1)/np.prod(batch['image'].shape[1:])]\n",
    "pred_label = np.concatenate(pred_label)\n",
    "label_masks_score = np.concatenate(label_masks_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "665c97ee-2058-4fc7-b7fd-1bebe256f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = dict()\n",
    "for area_id,logit,mask_score in zip(area_ids,pred_label,label_masks_score):\n",
    "    if area_id in pred_dict.keys():\n",
    "        pred_dict[area_id] += mask_score*(logit)\n",
    "    else:\n",
    "        pred_dict[area_id] = mask_score*logit\n",
    "pred_dict = {int(k):np.argmax(v) for k,v in pred_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cff1998-5f09-4a97-acbf-54c82b00637f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6439393939393939"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_res = pd.DataFrame([{int(i):j for i,j in zip(df_val.area_id,df_val.classes)},pred_dict],index = ['act_label','pred_label']).T\n",
    "act_label = df_val_res.act_label.values\n",
    "pred_label = df_val_res.pred_label.values\n",
    "(act_label==pred_label).sum()/len(act_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50c7d0e2-1c00-444f-adc8-e81ead3b9c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70        60\n",
      "           1       0.68      0.71      0.70        21\n",
      "           2       0.57      0.70      0.63        37\n",
      "           3       0.50      0.14      0.22        14\n",
      "\n",
      "    accuracy                           0.64       132\n",
      "   macro avg       0.61      0.56      0.56       132\n",
      "weighted avg       0.64      0.64      0.63       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(act_label, pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfadd470-5b27-4173-a46f-e31e4503fdf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crop_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>564 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     crop_type\n",
       "0          4.0\n",
       "1          2.0\n",
       "2          2.0\n",
       "3          2.0\n",
       "4          1.0\n",
       "..         ...\n",
       "560        2.0\n",
       "561        3.0\n",
       "562        1.0\n",
       "563        1.0\n",
       "564        3.0\n",
       "\n",
       "[564 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('submissions/S03_M2_ClassificationTraining_CONV1D_Result.csv')\n",
    "df = df[['crop_type']]\n",
    "df = pd.Series(df.iloc[:12]['crop_type'].tolist()+[np.nan]+df.iloc[12:]['crop_type'].tolist(),name='crop_type').to_frame()\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b2bafb-666b-4776-ba4a-d186559da936",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
