{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# Ref: https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/efficientnet.py\n",
    "# Install: pip install timm\n",
    "import timm\n",
    "from timm.models.efficientnet import default_cfgs \n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import transforms as T\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_68/1966511220.py:3: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  df_data = pd.Series(img_path,name=\"img_path\").to_frame()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [img_path, gender]\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = [i.replace('\\\\','/') for i in glob(\"./datasets/GenderDataset/*/*.jpg\")]\n",
    "genders = ['MAN', 'WOMAN', 'UNK']\n",
    "df_data = pd.Series(img_path,name=\"img_path\").to_frame()\n",
    "df_data['gender'] = df_data['img_path'].apply(lambda x: genders.index(x.split('/')[-2]))\n",
    "# df_data['gender'] = df_data['img_path'].apply(lambda x: x.split('/')[-2])\n",
    "\n",
    "df = df_data[df_data.gender!=2].reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['gender']==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_train, df_val \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df_train\u001b[38;5;241m.\u001b[39mshape,df_val\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_split.py:2175\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2172\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2174\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2175\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_split.py:1857\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   1854\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   1856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1857\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1858\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1859\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1860\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size,\n\u001b[1;32m   1861\u001b[0m                                             train_size)\n\u001b[1;32m   1862\u001b[0m     )\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(df, test_size=0.1, random_state=42)\n",
    "df_train.shape,df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m             img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_augmentation(img)\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m: img, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel[idx]}\n\u001b[0;32m---> 29\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m ImageDataset(\u001b[43mdf_train\u001b[49m, data_aug \u001b[38;5;241m=\u001b[39m augmentation)\n\u001b[1;32m     30\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m ImageDataset(df_val)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# dataloaders\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Dataset Loader\n",
    "img_size = 192\n",
    "augmentation = T.Compose([\n",
    "    T.RandomResizedCrop(img_size, scale=(0.08, 1.)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,df,img_size = img_size, data_aug = False):\n",
    "        self.img_path = list(df['img_path'])\n",
    "        self.label = list(df['gender'])\n",
    "        self.img_size = img_size\n",
    "        self.data_aug = data_aug\n",
    "        self.default_augmentation = T.Compose([\n",
    "                T.Resize((img_size,img_size)),\n",
    "                T.ToTensor(),\n",
    "            ])\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.img_path[idx])[:,:,::-1]\n",
    "        img = Image.fromarray(img)\n",
    "        if self.data_aug:\n",
    "            img = self.data_aug(img)\n",
    "        else:\n",
    "            img = self.default_augmentation(img)\n",
    "        return {'image': img, 'label': self.label[idx]}\n",
    "\n",
    "train_dataset = ImageDataset(df_train, data_aug = augmentation)\n",
    "val_dataset = ImageDataset(df_val)\n",
    "\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModel(torch.nn.Module):\n",
    "    def __init__(self,num_class=2):\n",
    "        super(ClassifierModel, self).__init__() \n",
    "        self.effnv2_b0_model = timm.create_model(\n",
    "                    'tf_efficientnetv2_b0',\n",
    "                    pretrained=True)\n",
    "        self.effnv2_b0_model.classifier = torch.nn.Linear(1280, num_class)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.effnv2_b0_model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ClassifierModel()\n",
    "model.effnv2_b0_model.conv_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2dSame(6, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from timm.models.layers.conv2d_same import Conv2dSame\n",
    "Conv2dSame(6, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ClassifierModel(torch.nn.Module):\n",
    "#     def __init__(self,n_dim1 = 256,num_class=10,dropout_rate=0.3):\n",
    "#         super(ClassifierModel, self).__init__() \n",
    "#         self.effnv2_b0_model = timm.create_model(\n",
    "#                     'tf_efficientnetv2_b0',\n",
    "#                     pretrained=True)\n",
    "#         self.droupout1 = torch.nn.Dropout(p=dropout_rate)\n",
    "#         self.droupout2 = torch.nn.Dropout(p=dropout_rate)\n",
    "\n",
    "#         self.fc1 = torch.nn.Linear(1000, n_dim1)\n",
    "#         self.fc2 = torch.nn.Linear(n_dim1, num_class)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.effnv2_b0_model(x)\n",
    "#         x = self.droupout1(x)\n",
    "#         x = self._mlp(x)\n",
    "#         return x\n",
    "    \n",
    "#     def _mlp(self,x):\n",
    "#         x = self.fc1(x)\n",
    "#         x = torch.nn.functional.leaky_relu(x)\n",
    "#         x = self.droupout2(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream(message) :\n",
    "    try:\n",
    "        sys.stdout.write(\"\\r{%s}\" % message)\n",
    "    except:\n",
    "        #Remove non-ASCII characters from message\n",
    "        message = ''.join(i for i in message if ord(i)<128)\n",
    "        sys.stdout.write(\"\\r{%s}\" % message)\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    LR_START = 1e-5\n",
    "    LR_MAX = 1e-3\n",
    "    LR_RAMPUP_EPOCHS = 5\n",
    "    LR_SUSTAIN_EPOCHS = 0\n",
    "    LR_STEP_DECAY = 0.75\n",
    "    if epoch < LR_RAMPUP_EPOCHS:\n",
    "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "        lr = LR_MAX\n",
    "    else:\n",
    "        lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//10)\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    return lr\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "def compute_accuracy(logit,label):\n",
    "    pred_label = logit.argmax(axis=1)\n",
    "    return (pred_label==label).sum()/logit.shape[0]\n",
    "    \n",
    "def compute_avg_w(l): # (data,num_batch)\n",
    "    sum_w_loss = 0\n",
    "    sum_w = 0\n",
    "    for i in l:\n",
    "        sum_w_loss+=i[0]*i[1]\n",
    "        sum_w+=i[1]\n",
    "    return sum_w_loss/sum_w\n",
    "\n",
    "def train(model,train_loader,test_loader,cfg,pretrained_model_checkpoint = None):\n",
    "    # model = DLA(num_classes=cfg.num_class).to(device)\n",
    "    model.to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    if pretrained_model_checkpoint:\n",
    "        model.load_state_dict(torch.load(pretrained_model_checkpoint)['state_dict'])\n",
    "\n",
    "    if not os.path.exists(cfg.output_directory):\n",
    "        os.mkdir(cfg.output_directory)\n",
    "    if cfg.save_to_tensorboard:\n",
    "        logger = SummaryWriter(os.path.join(cfg.output_directory, 'logs'))\n",
    "\n",
    "    \n",
    "\n",
    "    best_epoch = 0\n",
    "    best_val_loss = np.inf\n",
    "    for epoch in range(cfg.epochs):\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1,cfg.epochs))\n",
    "        adjust_learning_rate(optimizer, epoch)\n",
    "        # Training Model\n",
    "        model.train()\n",
    "        pred = []\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            start_time = time.time()\n",
    "            optimizer.zero_grad()\n",
    "            img = batch['image'].to(device)\n",
    "            label = batch['label'].to(device)\n",
    "            logit = model(img)\n",
    "            loss = criterion(logit,label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            num_step = i + len(train_loader) * epoch\n",
    "            step_loss = loss.item()\n",
    "            step_accuracy = compute_accuracy(logit,label).item()\n",
    "            pred+=[(step_accuracy,label.shape[0])]\n",
    "            msg = f\"| Epoch: {epoch+1}/{cfg.epochs} ({i+1}/{len(train_loader)}) | Loss: {step_loss:#.4} | Accuracy: {step_accuracy:#.4} | {1./(time.time() - start_time):#.3} steps/s | Step: {num_step//1000}k |\"\n",
    "            stream(msg)\n",
    "            if cfg.save_to_tensorboard:\n",
    "                logger.add_scalar('Loss/train', step_loss, num_step)\n",
    "                logger.add_scalar('Accuracy/train', step_accuracy, num_step)\n",
    "\n",
    "        epoch_train_accuracy =compute_avg_w(pred)\n",
    "        msg = f\"\\n\\n| Train Accuracy: {epoch_train_accuracy:#.4} |\"\n",
    "        print(msg)\n",
    "\n",
    "        # Evaluate Model\n",
    "        model.eval()\n",
    "        losses = []\n",
    "        pred = []\n",
    "\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            img = batch['image'].to(device)\n",
    "            label = batch['label'].to(device)\n",
    "            with torch.no_grad():\n",
    "                logit = model(img)\n",
    "                loss = criterion(logit,label)\n",
    "            losses+=[(loss.item(),label.shape[0])]\n",
    "            pred+=[(compute_accuracy(logit,label),label.shape[0])]\n",
    "\n",
    "        epoch_val_loss = compute_avg_w(losses)\n",
    "        epoch_val_accuracy =compute_avg_w(pred).item()\n",
    "\n",
    "        msg = f\"| Val Loss: {epoch_val_loss:#.4} | Val Accuracy: {epoch_val_accuracy:#.4} |\\n\"\n",
    "        print(msg)\n",
    "        if cfg.save_to_tensorboard:\n",
    "            logger.add_scalar('Loss/val', epoch_val_loss, epoch)\n",
    "            logger.add_scalar('Accuracy/val', epoch_val_accuracy, epoch)\n",
    "\n",
    "        save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer' : optimizer.state_dict(),\n",
    "            }, is_best=False, filename=os.path.join(cfg.output_directory, 'checkpoint_{:04d}.pth.tar'.format(epoch)))\n",
    "        \n",
    "        # Save Best Checkpoint\n",
    "        if best_val_loss>=epoch_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            best_epoch = epoch\n",
    "            # Save Best Checkpoint\n",
    "            save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer' : optimizer.state_dict(),\n",
    "                }, is_best=False, filename=os.path.join(cfg.output_directory, 'best_checkpoint.pth.tar'.format(epoch)))\n",
    "\n",
    "        # Early Stopping\n",
    "        # Check Val loss until no improvement after which training\n",
    "        # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n",
    "        if epoch-best_epoch>cfg.patience:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100\n",
      "{| Epoch: 1/100 (126/126) | Loss: 0.6525 | Accuracy: 0.6364 | 16.0 steps/s | Step: 0k |}\n",
      "\n",
      "| Train Accuracy: 0.5565 |\n",
      "| Val Loss: 0.6592 | Val Accuracy: 0.6323 |\n",
      "\n",
      "Epoch: 2/100\n",
      "{| Epoch: 2/100 (126/126) | Loss: 0.4877 | Accuracy: 0.7273 | 15.9 steps/s | Step: 0k |}\n",
      "\n",
      "| Train Accuracy: 0.7172 |\n",
      "| Val Loss: 0.4904 | Val Accuracy: 0.7590 |\n",
      "\n",
      "Epoch: 3/100\n",
      "{| Epoch: 3/100 (126/126) | Loss: 0.4280 | Accuracy: 0.7273 | 19.0 steps/s | Step: 0k |}\n",
      "\n",
      "| Train Accuracy: 0.7679 |\n",
      "| Val Loss: 0.4491 | Val Accuracy: 0.7937 |\n",
      "\n",
      "Epoch: 4/100\n",
      "{| Epoch: 4/100 (126/126) | Loss: 0.4439 | Accuracy: 0.8636 | 19.2 steps/s | Step: 0k |}\n",
      "\n",
      "| Train Accuracy: 0.7794 |\n",
      "| Val Loss: 0.5599 | Val Accuracy: 0.7152 |\n",
      "\n",
      "Epoch: 5/100\n",
      "{| Epoch: 5/100 (126/126) | Loss: 0.3833 | Accuracy: 0.8636 | 14.7 steps/s | Step: 0k |}\n",
      "\n",
      "| Train Accuracy: 0.7865 |\n",
      "| Val Loss: 0.5574 | Val Accuracy: 0.7186 |\n",
      "\n",
      "Epoch: 6/100\n",
      "{| Epoch: 6/100 (126/126) | Loss: 0.5530 | Accuracy: 0.6818 | 16.7 steps/s | Step: 0k |}\n",
      "\n",
      "| Train Accuracy: 0.7828 |\n",
      "| Val Loss: 0.5223 | Val Accuracy: 0.7242 |\n",
      "\n",
      "Epoch: 7/100\n",
      "{| Epoch: 7/100 (126/126) | Loss: 0.4316 | Accuracy: 0.6818 | 16.9 steps/s | Step: 0k |}\n",
      "\n",
      "| Train Accuracy: 0.8038 |\n",
      "| Val Loss: 0.5057 | Val Accuracy: 0.7511 |\n",
      "\n",
      "Epoch: 8/100\n",
      "{| Epoch: 8/100 (126/126) | Loss: 0.3795 | Accuracy: 0.7727 | 17.6 steps/s | Step: 1k |}\n",
      "\n",
      "| Train Accuracy: 0.8105 |\n",
      "| Val Loss: 0.5233 | Val Accuracy: 0.7265 |\n",
      "\n",
      "Epoch: 9/100\n",
      "{| Epoch: 9/100 (126/126) | Loss: 0.3582 | Accuracy: 0.8636 | 16.5 steps/s | Step: 1k |}\n",
      "\n",
      "| Train Accuracy: 0.8251 |\n",
      "| Val Loss: 0.5087 | Val Accuracy: 0.7657 |\n",
      "\n",
      "Epoch: 10/100\n",
      "{| Epoch: 10/100 (126/126) | Loss: 0.5466 | Accuracy: 0.7273 | 18.8 steps/s | Step: 1k |}\n",
      "\n",
      "| Train Accuracy: 0.8231 |\n",
      "| Val Loss: 0.5926 | Val Accuracy: 0.7365 |\n",
      "\n",
      "Epoch: 11/100\n",
      "{| Epoch: 11/100 (126/126) | Loss: 0.4995 | Accuracy: 0.8182 | 18.2 steps/s | Step: 1k |}\n",
      "\n",
      "| Train Accuracy: 0.8462 |\n",
      "| Val Loss: 0.4403 | Val Accuracy: 0.8094 |\n",
      "\n",
      "Epoch: 12/100\n",
      "{| Epoch: 12/100 (126/126) | Loss: 0.3645 | Accuracy: 0.8636 | 17.1 steps/s | Step: 1k |}\n",
      "\n",
      "| Train Accuracy: 0.8372 |\n",
      "| Val Loss: 0.4941 | Val Accuracy: 0.7601 |\n",
      "\n",
      "Epoch: 13/100\n",
      "{| Epoch: 13/100 (126/126) | Loss: 0.3730 | Accuracy: 0.8636 | 19.0 steps/s | Step: 1k |}\n",
      "\n",
      "| Train Accuracy: 0.8431 |\n",
      "| Val Loss: 0.5775 | Val Accuracy: 0.7623 |\n",
      "\n",
      "Epoch: 14/100\n",
      "{| Epoch: 14/100 (126/126) | Loss: 0.4150 | Accuracy: 0.7727 | 18.4 steps/s | Step: 1k |}\n",
      "\n",
      "| Train Accuracy: 0.8569 |\n",
      "| Val Loss: 0.6877 | Val Accuracy: 0.7197 |\n",
      "\n",
      "Epoch: 15/100\n",
      "{| Epoch: 15/100 (126/126) | Loss: 0.5892 | Accuracy: 0.7273 | 18.8 steps/s | Step: 1k |}\n",
      "\n",
      "| Train Accuracy: 0.8507 |\n",
      "| Val Loss: 0.4894 | Val Accuracy: 0.7769 |\n",
      "\n",
      "Epoch: 16/100\n",
      "{| Epoch: 16/100 (126/126) | Loss: 0.3397 | Accuracy: 0.8636 | 17.0 steps/s | Step: 2k |}\n",
      "\n",
      "| Train Accuracy: 0.8679 |\n",
      "| Val Loss: 0.5479 | Val Accuracy: 0.7892 |\n",
      "\n",
      "Epoch: 17/100\n",
      "{| Epoch: 17/100 (126/126) | Loss: 0.3906 | Accuracy: 0.8636 | 18.6 steps/s | Step: 2k |}\n",
      "\n",
      "| Train Accuracy: 0.8735 |\n",
      "| Val Loss: 0.4391 | Val Accuracy: 0.7870 |\n",
      "\n",
      "Epoch: 18/100\n",
      "{| Epoch: 18/100 (126/126) | Loss: 0.2617 | Accuracy: 0.9091 | 18.4 steps/s | Step: 2k |}\n",
      "\n",
      "| Train Accuracy: 0.8776 |\n",
      "| Val Loss: 0.5497 | Val Accuracy: 0.7735 |\n",
      "\n",
      "Epoch: 19/100\n",
      "{| Epoch: 19/100 (126/126) | Loss: 0.2642 | Accuracy: 0.8636 | 16.8 steps/s | Step: 2k |}\n",
      "\n",
      "| Train Accuracy: 0.8786 |\n",
      "| Val Loss: 0.4767 | Val Accuracy: 0.8038 |\n",
      "\n",
      "Epoch: 20/100\n",
      "{| Epoch: 20/100 (126/126) | Loss: 0.1022 | Accuracy: 1.000 | 15.9 steps/s | Step: 2k |}}\n",
      "\n",
      "| Train Accuracy: 0.8913 |\n",
      "| Val Loss: 0.6956 | Val Accuracy: 0.7377 |\n",
      "\n",
      "Epoch: 21/100\n",
      "{| Epoch: 21/100 (126/126) | Loss: 0.1978 | Accuracy: 0.9545 | 19.1 steps/s | Step: 2k |}\n",
      "\n",
      "| Train Accuracy: 0.8938 |\n",
      "| Val Loss: 0.5727 | Val Accuracy: 0.7567 |\n",
      "\n",
      "Epoch: 22/100\n",
      "{| Epoch: 22/100 (126/126) | Loss: 0.1644 | Accuracy: 0.8636 | 18.6 steps/s | Step: 2k |}\n",
      "\n",
      "| Train Accuracy: 0.8847 |\n",
      "| Val Loss: 0.7195 | Val Accuracy: 0.7365 |\n",
      "\n",
      "Epoch: 23/100\n",
      "{| Epoch: 23/100 (126/126) | Loss: 0.2273 | Accuracy: 0.9091 | 18.1 steps/s | Step: 2k |}\n",
      "\n",
      "| Train Accuracy: 0.8927 |\n",
      "| Val Loss: 0.5275 | Val Accuracy: 0.7747 |\n",
      "\n",
      "Epoch: 24/100\n",
      "{| Epoch: 24/100 (126/126) | Loss: 0.3471 | Accuracy: 0.8182 | 18.1 steps/s | Step: 3k |}\n",
      "\n",
      "| Train Accuracy: 0.8965 |\n",
      "| Val Loss: 0.7026 | Val Accuracy: 0.7096 |\n",
      "\n",
      "Epoch: 25/100\n",
      "{| Epoch: 25/100 (126/126) | Loss: 0.2366 | Accuracy: 0.9091 | 18.1 steps/s | Step: 3k |}\n",
      "\n",
      "| Train Accuracy: 0.8939 |\n",
      "| Val Loss: 0.5993 | Val Accuracy: 0.7668 |\n",
      "\n",
      "Epoch: 26/100\n",
      "{| Epoch: 26/100 (126/126) | Loss: 0.2376 | Accuracy: 0.9091 | 16.5 steps/s | Step: 3k |}}\n",
      "\n",
      "| Train Accuracy: 0.9105 |\n",
      "| Val Loss: 0.5060 | Val Accuracy: 0.8139 |\n",
      "\n",
      "Epoch: 27/100\n",
      "{| Epoch: 27/100 (126/126) | Loss: 0.2467 | Accuracy: 0.9091 | 18.7 steps/s | Step: 3k |}\n",
      "\n",
      "| Train Accuracy: 0.9096 |\n",
      "| Val Loss: 0.5773 | Val Accuracy: 0.7702 |\n",
      "\n",
      "Epoch: 28/100\n",
      "{| Epoch: 28/100 (126/126) | Loss: 0.08067 | Accuracy: 1.000 | 18.4 steps/s | Step: 3k |}\n",
      "\n",
      "| Train Accuracy: 0.9196 |\n",
      "| Val Loss: 0.5109 | Val Accuracy: 0.7982 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class cfg:\n",
    "    output_directory = \"./weight/gender_cls_effnv2b0_checkpoint_from_MOCOv3_v2\"\n",
    "    epochs = 100\n",
    "    num_class = 9\n",
    "    # Early Stopping Params\n",
    "    patience = 10 # Number of epochs with no improvement after which training will be stopped.\n",
    "    save_to_tensorboard = True # tensorboard --logdir ./logs\n",
    "model = ClassifierModel()\n",
    "model.effnv2_b0_model.load_state_dict(torch.load('./weight/moco_checkpoint_gender_cls_v2/effnv2_b0_model_pretrained.pth.tar')['state_dict'] ,strict=False)\n",
    "train(model,train_loader,test_loader,cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"status\":200,\"message\":\"ok\"}'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from line_notify import send_line_notify\n",
    "send_line_notify('Finish Training Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100\n",
      "{| Epoch: 1/100 (126/126) | Loss: 0.6769 | Accuracy: 0.6364 | 18.4 steps/s | Step: 0k |}\n",
      "\n",
      "| Train Accuracy: 0.5860 |\n",
      "| Val Loss: 0.6432 | Val Accuracy: 0.6256 |\n",
      "\n",
      "Epoch: 2/100\n",
      "{| Epoch: 2/100 (126/126) | Loss: 0.4488 | Accuracy: 0.6818 | 17.2 steps/s | Step: 0k |}\n",
      "\n",
      "| Train Accuracy: 0.7203 |\n",
      "| Val Loss: 0.4767 | Val Accuracy: 0.7489 |\n",
      "\n",
      "Epoch: 3/100\n",
      "{| Epoch: 3/100 (126/126) | Loss: 0.4159 | Accuracy: 0.7273 | 18.8 steps/s | Step: 0k |}\n",
      "\n",
      "| Train Accuracy: 0.7701 |\n",
      "| Val Loss: 0.5054 | Val Accuracy: 0.7601 |\n",
      "\n",
      "Epoch: 4/100\n",
      "{| Epoch: 4/100 (126/126) | Loss: 0.5821 | Accuracy: 0.6818 | 17.7 steps/s | Step: 0k |}\n",
      "\n",
      "| Train Accuracy: 0.7851 |\n",
      "| Val Loss: 0.4417 | Val Accuracy: 0.7982 |\n",
      "\n",
      "Epoch: 5/100\n",
      "{| Epoch: 5/100 (126/126) | Loss: 0.5402 | Accuracy: 0.7727 | 17.9 steps/s | Step: 0k |}\n",
      "\n",
      "| Train Accuracy: 0.7938 |\n",
      "| Val Loss: 0.4798 | Val Accuracy: 0.7522 |\n",
      "\n",
      "Epoch: 6/100\n",
      "{| Epoch: 6/100 (126/126) | Loss: 0.3613 | Accuracy: 0.8636 | 16.3 steps/s | Step: 0k |}\n",
      "\n",
      "| Train Accuracy: 0.7947 |\n",
      "| Val Loss: 0.6393 | Val Accuracy: 0.7074 |\n",
      "\n",
      "Epoch: 7/100\n",
      "{| Epoch: 7/100 (126/126) | Loss: 0.4257 | Accuracy: 0.7727 | 18.6 steps/s | Step: 0k |}\n",
      "\n",
      "| Train Accuracy: 0.7982 |\n",
      "| Val Loss: 0.5699 | Val Accuracy: 0.7489 |\n",
      "\n",
      "Epoch: 8/100\n",
      "{| Epoch: 8/100 (126/126) | Loss: 0.4053 | Accuracy: 0.9091 | 19.1 steps/s | Step: 1k |}\n",
      "\n",
      "| Train Accuracy: 0.8199 |\n",
      "| Val Loss: 0.4955 | Val Accuracy: 0.7567 |\n",
      "\n",
      "Epoch: 9/100\n",
      "{| Epoch: 9/100 (126/126) | Loss: 0.5365 | Accuracy: 0.5909 | 19.0 steps/s | Step: 1k |}\n",
      "\n",
      "| Train Accuracy: 0.8332 |\n",
      "| Val Loss: 0.5447 | Val Accuracy: 0.7141 |\n",
      "\n",
      "Epoch: 10/100\n",
      "{| Epoch: 10/100 (126/126) | Loss: 0.3801 | Accuracy: 0.7727 | 18.8 steps/s | Step: 1k |}\n",
      "\n",
      "| Train Accuracy: 0.8277 |\n",
      "| Val Loss: 0.4554 | Val Accuracy: 0.7937 |\n",
      "\n",
      "Epoch: 11/100\n",
      "{| Epoch: 11/100 (126/126) | Loss: 0.3442 | Accuracy: 0.8182 | 18.4 steps/s | Step: 1k |}\n",
      "\n",
      "| Train Accuracy: 0.8403 |\n",
      "| Val Loss: 0.5157 | Val Accuracy: 0.7679 |\n",
      "\n",
      "Epoch: 12/100\n",
      "{| Epoch: 12/100 (126/126) | Loss: 0.3410 | Accuracy: 0.8182 | 16.7 steps/s | Step: 1k |}\n",
      "\n",
      "| Train Accuracy: 0.8462 |\n",
      "| Val Loss: 0.5210 | Val Accuracy: 0.7735 |\n",
      "\n",
      "Epoch: 13/100\n",
      "{| Epoch: 13/100 (126/126) | Loss: 0.2275 | Accuracy: 0.9545 | 18.7 steps/s | Step: 1k |}\n",
      "\n",
      "| Train Accuracy: 0.8554 |\n",
      "| Val Loss: 0.5190 | Val Accuracy: 0.7892 |\n",
      "\n",
      "Epoch: 14/100\n",
      "{| Epoch: 14/100 (126/126) | Loss: 0.4055 | Accuracy: 0.7727 | 18.1 steps/s | Step: 1k |}\n",
      "\n",
      "| Train Accuracy: 0.8498 |\n",
      "| Val Loss: 0.5492 | Val Accuracy: 0.7500 |\n",
      "\n",
      "Epoch: 15/100\n",
      "{| Epoch: 15/100 (126/126) | Loss: 0.3805 | Accuracy: 0.8182 | 18.7 steps/s | Step: 1k |}\n",
      "\n",
      "| Train Accuracy: 0.8462 |\n",
      "| Val Loss: 1.120 | Val Accuracy: 0.6525 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class cfg:\n",
    "    output_directory = \"./weight/gender_cls_effnv2b0_checkpoint_from_MOCOv3_v1\"\n",
    "    epochs = 100\n",
    "    num_class = 9\n",
    "    # Early Stopping Params\n",
    "    patience = 10 # Number of epochs with no improvement after which training will be stopped.\n",
    "    save_to_tensorboard = True # tensorboard --logdir ./logs\n",
    "model = ClassifierModel()\n",
    "model.effnv2_b0_model.load_state_dict(torch.load('./weight/moco_checkpoint_gender_cls_v1/effnv2_b0_model_pretrained.pth.tar')['state_dict'] ,strict=False)\n",
    "train(model,train_loader,test_loader,cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"status\":200,\"message\":\"ok\"}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from line_notify import send_line_notify\n",
    "send_line_notify('Finish Training Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ClassifierModel()\n",
    "model.load_state_dict(torch.load('./weight/gender_cls_effnv2b0_checkpoint_from_MOCOv3_v1/best_checkpoint.pth.tar')['state_dict'] ,strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = []\n",
    "actual_label = []\n",
    "model.cuda().eval()\n",
    "for batch in test_loader:\n",
    "    img = batch['image'].cuda()\n",
    "    with torch.no_grad():\n",
    "        pred = model(img).cpu().numpy().argmax(axis=1)\n",
    "    pred_label += [pred]\n",
    "    actual_label += [batch['label'].numpy()]\n",
    "\n",
    "pred_label = np.concatenate(pred_label)        \n",
    "actual_label = np.concatenate(actual_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7982062780269058"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_label==actual_label).sum()/len(actual_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "438727c8858bc46e257ba69863512eb04c8e9f5db9a1c7102296af502b4092eb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
